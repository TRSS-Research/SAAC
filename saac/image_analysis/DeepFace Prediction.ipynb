{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f26d90-c631-4fe1-855f-3a1f7fb36790",
   "metadata": {},
   "source": [
    "# Face Predictions using DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d9c600-3f49-44a0-a789-878d98d70bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import cv2 as cv\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from deepface import DeepFace\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from saac.utils import cv_imshow, color_show, quadrant_bboxes, crop_bbox, draw_bbox\n",
    "from saac.models import IdentityClassifier, CalibratedGenderModel, SkinColorMeanExtractor\n",
    "from saac.process import ImageEqualizer, MidJourneyProcessor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample Midjourney image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "midjourney_raw_root = Path('../../data/images/raw')\n",
    "\n",
    "img_path = list(midjourney_raw_root.glob('*.png'))[0]\n",
    "\n",
    "img_2x2 = cv.imread(str(img_path))\n",
    "cv_imshow(img_2x2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Number quadrants and crop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, bbox in enumerate(quadrant_bboxes(img_2x2.shape[:2])):\n",
    "    draw_bbox(img_2x2, bbox, text=f'{i}', color=(0, 255, 255))\n",
    "\n",
    "cv_imshow(img_2x2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quadrant = 2\n",
    "img_quad = crop_bbox(img_2x2, quadrant_bboxes(img_2x2.shape[:2])[quadrant])\n",
    "cv_imshow(img_quad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### DeepFace predictions on quadrant"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processor = MidJourneyProcessor()\n",
    "\n",
    "predictions = processor.quadrant_predictions(img_2x2)\n",
    "pprint(predictions[quadrant])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_face = crop_bbox(img_2x2, predictions[quadrant]['bbox'])\n",
    "color = predictions[quadrant]['skin color']\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
    "cv_imshow(img_face, ax=ax[0])\n",
    "color_show(color, ax=ax[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DeepFace predictions on dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load desired gender detector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_default_models = {\n",
    "    'age': DeepFace.build_model('Age'),\n",
    "    'gender': DeepFace.build_model('Gender'),\n",
    "    'emotion': DeepFace.build_model('Emotion'),\n",
    "    'race': DeepFace.build_model('Race')\n",
    "}\n",
    "\n",
    "calibrated_model_path = Path('../../models/gender_model_default_calibrated.joblib')\n",
    "calibrated_clf = joblib.load(calibrated_model_path)\n",
    "\n",
    "calibrated_gender_model = CalibratedGenderModel(\n",
    "    gender_model=df_default_models['gender'],\n",
    "    calibrator=calibrated_clf\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# gender_model = df_default_models['gender']\n",
    "gender_model = calibrated_gender_model\n",
    "\n",
    "color_extractor = SkinColorMeanExtractor()\n",
    "\n",
    "kwargs = {\n",
    "    'equalizer': True,\n",
    "    'actions': ('gender', 'skin'),\n",
    "    'models': { 'gender': gender_model },\n",
    "    'extractor': color_extractor,\n",
    "    'detector_backend': 'mtcnn'\n",
    "}\n",
    "\n",
    "def prompt_extract(path: str) -> str:\n",
    "    return ' '.join(path.split('_')[1:-1])\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "for quad_path in tqdm(list(midjourney_raw_root.glob('*.png'))):\n",
    "    quad_image = cv.imread(str(quad_path))\n",
    "    prompt = prompt_extract(quad_path.stem)\n",
    "    quad_predictions = [p if p else {} for p in processor.quadrant_predictions(quad_image, **kwargs)]\n",
    "    for idx, pred in enumerate(quad_predictions):\n",
    "        pred['image'] = quad_path.stem\n",
    "        pred['quadrant'] = idx\n",
    "        pred['prompt'] = prompt\n",
    "    all_predictions.extend(quad_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0af08e-7f64-4d08-84f5-57aca47fb639",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.json_normalize(all_predictions)\n",
    "\n",
    "lead_cols = [\n",
    "    'prompt',\n",
    "    'image',\n",
    "    'quadrant',\n",
    "    'bbox'\n",
    "]\n",
    "\n",
    "results_df = results_df.reindex(columns=lead_cols+[col for col in results_df.columns if col not in lead_cols])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f074af-efdc-442d-96c6-b089c1f28dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(Path('./midjourney_deepface_calibrated_equalized.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c96f740-a236-45b1-82c4-bfd513cbd317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:saac_p38]",
   "language": "python",
   "name": "conda-env-saac_p38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}